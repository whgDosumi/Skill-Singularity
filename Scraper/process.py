import csv
from jobspy import scrape_jobs
import json
import os
import pandas as pd
import re

wd = os.path.dirname(__file__)

if __name__ == "__main__":
    # Import the skills json (we'll get this from a database later hopefully)
    with open(os.path.join(wd, "skills.json"), "r") as f:
        skills = json.load(f)

    # Regex to match each skill in skills
    skill_pattern = r"\b(" + "|".join(re.escape(skill.lower()) for skill in skills) + r")\b"

    # Import the json generated by scrape.py as dataframe
    job_df = pd.read_json(os.path.join(wd, "jobs.json"))
    # New column that contains all of the descriptions in lowercase
    job_df["desc_lower"] = job_df["description"].fillna(" ").str.lower()
    # New column with a list of each matched skill
    job_df["skills_matched"] = job_df["desc_lower"].str.findall(skill_pattern)

    # Get counts for each skill across the given jobs
    counts = {}
    for skill in skills:
        count = job_df["skills_matched"].apply(lambda matches: skill in matches).sum()
        if count > 0:
            counts[skill] = count

    # Sort and present the skills in order
    counts = pd.Series(counts).sort_values(ascending=False)
    print(counts.head(50))